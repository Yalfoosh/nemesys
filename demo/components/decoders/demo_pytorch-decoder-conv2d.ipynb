{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Memory System - PyTorchDecoderConv2D demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_FOLDER = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_KEY = \"--PYTORCH_DECODER_CONV2D_DEMO_IN_ROOT\"\n",
    "\n",
    "if (\n",
    "    CD_KEY not in os.environ\n",
    "    or os.environ[CD_KEY] is None\n",
    "    or len(os.environ[CD_KEY]) == 0\n",
    "    or os.environ[CD_KEY] == \"false\"\n",
    "):\n",
    "    %cd -q ../../..\n",
    "    \n",
    "    ROOT_FOLDER = Path(os.getcwd()).relative_to(os.getcwd())\n",
    "    CURRENT_FOLDER = CURRENT_FOLDER.relative_to(ROOT_FOLDER.absolute())\n",
    "    \n",
    "os.environ[CD_KEY] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder:    .\n",
      "Current folder: demo/components/decoders\n"
     ]
    }
   ],
   "source": [
    "print(f\"Root folder:    {ROOT_FOLDER}\")\n",
    "print(f\"Current folder: {CURRENT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemesys.modelling.blocks.pytorch_block import PyTorchBlock\n",
    "from nemesys.modelling.decoders.modules.pytorch_decoder_conv2d import PyTorchDecoderConv2D\n",
    "from nemesys.modelling.stores.pytorch_list_store import PyTorchListStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = PyTorchListStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 5\n",
    "n_shapes_per_block_interval = (1, 3)\n",
    "base_shape = (3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_tensors = [\n",
    "    torch.normal(mean=0, std=1, size=(n_shapes, *base_shape))\n",
    "    for n_shapes in torch.randint(*n_shapes_per_block_interval, (n_blocks,))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    PyTorchBlock.from_tensor(block_tensor)\n",
    "    for block_tensor in block_tensors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.set_all(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.2768, -0.4237,  1.1168, -2.6320],\n",
      "         [ 1.2782,  0.6363, -0.4488,  0.5287],\n",
      "         [ 0.8698, -0.9242, -1.0456,  0.8315]],\n",
      "\n",
      "        [[-0.0737, -0.0691, -0.3661, -1.2948],\n",
      "         [-0.5853,  0.4625,  2.0179,  1.3274],\n",
      "         [-0.9873, -0.1482,  0.4677,  0.2914]]]),\n",
      " tensor([[[ 1.5072, -0.0156, -1.5723, -0.9636],\n",
      "         [ 1.0055,  0.8238, -2.7285,  0.7499],\n",
      "         [-0.6132,  0.5981, -1.8857,  2.0812]],\n",
      "\n",
      "        [[ 0.3369, -0.5577, -1.1800,  0.9843],\n",
      "         [ 0.7493, -0.1581, -0.3657, -1.1130],\n",
      "         [ 1.0964, -1.0983, -0.9802,  1.1958]]]),\n",
      " tensor([[[ 1.1391,  0.7812, -2.0493, -0.0540],\n",
      "         [-0.3671, -0.4420, -0.1300, -1.0198],\n",
      "         [-0.9384, -0.0403, -0.3097,  1.5668]]]),\n",
      " tensor([[[ 0.7676,  2.1379,  0.1144, -0.5096],\n",
      "         [-0.3462,  1.2244, -0.3620, -1.2454],\n",
      "         [-0.5277,  2.3552,  0.9707, -0.0582]],\n",
      "\n",
      "        [[-1.3268, -1.3440,  0.0427,  0.5252],\n",
      "         [ 0.9843, -0.5161,  1.0801,  0.1506],\n",
      "         [-0.8568,  0.3377, -1.0494, -0.8169]]]),\n",
      " tensor([[[ 1.0078, -0.5506,  1.9111, -1.4799],\n",
      "         [ 0.3001,  1.5835,  0.8154, -0.1482],\n",
      "         [ 1.1392, -0.6086, -1.3361,  0.3680]],\n",
      "\n",
      "        [[ 0.8480, -0.5570,  0.1443,  0.5091],\n",
      "         [-1.0956,  0.6625,  1.2482, -0.4166],\n",
      "         [ 0.9627,  1.8214, -0.9782, -0.2971]]])]\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 4\n",
    "\n",
    "window_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = PyTorchDecoderConv2D(\n",
    "    in_channels = in_channels,\n",
    "    out_channels = out_channels,\n",
    "    kernel_size = (window_length, math.prod(base_shape))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = decoder(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': tensor([[[[     0.0511],\n",
      "          [    -1.1183],\n",
      "          [    -0.7146],\n",
      "          [    -0.4854],\n",
      "          [    -0.7013],\n",
      "          [    -0.6692],\n",
      "          [    -0.1796]],\n",
      "\n",
      "         [[    -0.8493],\n",
      "          [    -0.1077],\n",
      "          [    -0.7488],\n",
      "          [     0.2027],\n",
      "          [    -0.0007],\n",
      "          [     0.7154],\n",
      "          [    -0.5636]],\n",
      "\n",
      "         [[    -0.0723],\n",
      "          [     0.0273],\n",
      "          [    -0.0062],\n",
      "          [    -0.4032],\n",
      "          [     0.3041],\n",
      "          [    -0.4063],\n",
      "          [    -0.0484]],\n",
      "\n",
      "         [[     0.8434],\n",
      "          [    -0.7737],\n",
      "          [     0.2703],\n",
      "          [     1.3030],\n",
      "          [    -1.0452],\n",
      "          [     0.9108],\n",
      "          [    -0.2948]]]], grad_fn=<ThnnConv2DBackward>)}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemesys",
   "language": "python",
   "name": "nemesys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
